# obliq-2: Architecture Design for a Visual Modeling & Simulation Web Application

## Overview and Technology Stack

This application is a web-based visual modeling and simulation tool, similar in spirit to Simulink. It enables users to **construct, test, and simulate block diagram models** in the browser, then generate C code for embedded deployment. The solution is built with **Next.js** as the frontend framework (leveraging its full-stack capabilities) and **Supabase** as the backend-as-a-service (handling database storage and user authentication). The primary data model (the user-created diagrams) is stored as JSON in a Postgres database (via Supabase). Using Supabase simplifies backend infrastructure since it provides authentication and a Postgres database with built-in JSON support (using JSONB columns) and row-level security for multi-user data separation. The architecture prioritizes clarity, simplicity, and performance, avoiding complex collaborative features and focusing on single-user editing sessions.

## High-Level System Architecture


*High-level architecture of the visual modeling application.* The system consists of a **Next.js frontend** (the user interface and client-side logic) and **Next.js API routes** (serverless functions) that together form the application, with **Supabase** providing authentication and database services. The **user’s browser** runs the Next.js frontend, including the **visual modeling canvas** and an in-browser **simulation engine**. The browser communicates directly with Supabase (via Supabase’s JavaScript client) for most CRUD operations and authentication flows, and it communicates with Next.js API routes for specialized tasks like code generation or automated external triggers. Supabase’s database stores persistent data (model documents, user profiles, etc.), and Supabase Auth manages user sign-up/sign-in and session tokens. The **Next.js API backend** (part of the same Next application) handles operations that are better done server-side (e.g. preparing a downloadable code bundle or responding to external API calls), and it can securely interact with the Supabase database (using service role credentials or Supabase client on the server) when needed. In summary, the browser is responsible for interactive modeling and simulation, Supabase handles data persistence and auth, and Next.js API routes provide auxiliary services (code export, automation hooks) and integrate all pieces.

## Project Structure and Folder Organization

The project follows a clean, modular folder structure to organize different concerns. Next.js does not enforce a specific organization, so we structure files by feature and functionality for clarity. Below is an outline of the key directories and files, with each part explained:

* **`/app`** (or `pages/` in older Next.js versions): Contains the Next.js pages and route handlers. Using Next.js App Router, we structure pages as React Server Components where appropriate for data fetching.

  * **`app/page.tsx`** – The landing page (e.g. a home or dashboard). If the user is not authenticated, it might show marketing info or a login link; if authenticated, it can redirect to the model list.
  * **`app/login/page.tsx`** – Login (and sign-up) page for user authentication. It uses Supabase Auth (via the JS client or Supabase Auth UI) to handle user credentials.
  * **`app/models/page.tsx`** – Models dashboard page, listing the user’s saved models. This page fetches model metadata from Supabase (could be done via a React Server Component that uses the Supabase client with the user's session token). It displays a list of models and a button to create a new model.
  * **`app/models/[id]/page.tsx`** – The **model editor page** for constructing and simulating a specific model. It is the core of the application’s UI, loading the model JSON from Supabase (via client-side fetch or server-side prefetch) and then rendering the visual canvas. This page likely uses a mix of server and client components: for example, the initial model data can be fetched on the server (for faster load) and passed to a client component that manages the interactive editing. It also provides UI controls for actions like *Save*, *Run Simulation*, *Generate C Code*, *Download JSON*, etc.
  * **`app/api/simulate/route.ts`** – (Optional) API route to run simulation on the server. If the simulation is simple enough, we might *not* need this and instead run simulations in the browser. However, if we choose server-side simulation for consistency or offloading work, this endpoint would accept a model (ID or JSON) and perform the simulation, returning results (e.g. computed signal traces).
  * **`app/api/generate-code/route.ts`** – API route to handle **C code generation**. When the user requests a PlatformIO C library export, the frontend calls this endpoint (likely via a POST request containing the model ID or JSON). The route will load the model (if only an ID was sent), then invoke the code generation service to produce a C code bundle (source files). The response could be a file download (e.g. a zip archive of the library) or a JSON with a link to a file in Supabase Storage. This isolates the heavy or sensitive operation of code generation on the server side.
  * **`app/api/automations/[token]/route.ts`** – API route for the **automation API**. This endpoint allows external systems (like CI/CD pipelines or validation tools) to trigger actions on a model. For example, an external request could hit `POST /api/automations/{token}` with a payload specifying a model ID and an action (simulate, validate, or code-generate). A secure token (or an API key) in the URL or headers is used to authenticate these external requests (to avoid requiring a user session). Internally, this route verifies the token, then performs the requested action by calling the appropriate logic (e.g., running a simulation or generating code) and returns a result (like success status or generated artifacts). By design, this API route decouples external automation from the UI, enabling integration with CI systems without exposing the main app’s user session mechanism.

* **`/components`**: Reusable **React components** for the UI, especially those used on the modeling canvas and related UI panels.

  * **`components/Canvas.tsx`** – The **visual modeling canvas** component. This component provides a drawing area (using HTML5 Canvas or SVG/React components) where block diagram elements (blocks and connecting wires) are rendered. It handles drag-and-drop placement of blocks, drawing of connection lines between ports, and selection/highlighting of elements. The Canvas component likely uses internal state or context to track what’s being dragged or selected, and it delegates events (like drop or wire connection) to higher-level handlers.
  * **`components/Block.tsx`** – A component representing an individual **Block** (e.g., a Sum block, Multiplication block, etc.). Each Block knows how to render its icon/symbol and has defined input/output ports. It might be implemented as a draggable item. This component might also include UI for configuring block parameters (for blocks that have parameters, such as a Laplace Transfer Function which has coefficients).
  * **`components/Port.tsx`** – A sub-component for an input or output port on a block. Ports are anchor points for connections. This component might handle user interactions for starting or ending a wire connection (e.g., click and drag from an output port to an input port).
  * **`components/Wire.tsx`** – A component (or an SVG path) representing a **wire connection** between blocks. Wires can be drawn as SVG lines or Bezier curves connecting an output port to an input port. This component likely calculates a path based on the positions of the connected ports. It may also handle user interaction (e.g., clicking a wire might highlight it or allow deletion).
  * **`components/BlockLibrarySidebar.tsx`** – A sidebar component that lists all available primitive blocks (Sum, Multiply, Transfer Function, Signal Display, Logger, Input/Output ports, etc.) and possibly user-defined Subsystems. Users can drag new blocks from this palette onto the canvas. This component organizes blocks into categories and provides a search or filter for convenience if the library grows.
  * **`components/PropertiesPanel.tsx`** – A panel for editing properties of the currently selected block or subsystem. For instance, if the user selects a Transfer Function block, this panel would show input fields for numerator/denominator coefficients. For an Input/Output port, it may allow naming the signal (which is important because signal names will carry into code generation). The panel writes changes back to the model state.

* **`/lib`**: Utility modules and services (plain TypeScript/JavaScript modules that contain business logic, helpers, or integrations).

  * **`lib/supabaseClient.ts`** – A module to initialize and export the Supabase client (with the project URL and anon API key). This is used on the client side to interact with Supabase. It might also handle setting up Supabase authentication state listener and refreshing the JWT as needed.
  * **`lib/auth.tsx`** – (Optional) Utilities for authentication, possibly a React context provider that wraps the Supabase auth functions. This could provide React hooks like `useUser()` or `useSession()` throughout the app. It might also implement route guarding (for example, redirecting to login if no user session).
  * **`lib/simulationEngine.ts`** – The **simulation logic** implementation. This module contains functions to execute a model step-by-step. For simplicity and performance, the simulation can run in the browser (no network latency). The simulation engine would take the model JSON (or an in-memory representation of the block graph) and iteratively compute outputs of blocks over time steps. It likely supports both continuous (differential equation) blocks like transfer functions and discrete logic for algebraic blocks. For interactive use, this could be run in a Web Worker to keep the UI responsive if needed. The simulation engine updates the values of Signal Display blocks and logs data for Signal Logger blocks as the simulation progresses. Because our app is focusing on simplicity and not real-time collaboration, the simulation state lives purely on the client during a session – the results are not persisted in the database, they are just visualized or available for download if the user explicitly exports them.
  * **`lib/codeGeneration.ts`** – The **C Code generation service**. This module includes functions that transform a model JSON into C code files. It likely iterates through the blocks and connections to produce C structures and functions. For example, it may generate a `init()` function to initialize all blocks, an `update(step_time)` function to update the simulation each tick, and data structures for each block’s state. It uses the preserved signal names from the model for variable and function names to ensure the generated code is understandable. The code generation could use templates for PlatformIO (e.g., generating a library with a `library.properties` if targeting Arduino, or a PlatformIO `src/` folder with code). This module can be used both on the server (for the API route that delivers a file) and potentially on the client (if we wanted to preview code). However, generating a downloadable library (especially if it involves bundling multiple files into a zip) is better done server-side. The output of code generation is not stored in the database; it’s generated on-demand and provided to the user (or external caller) for download.
  * **`lib/modelSchema.ts`** – Definition of the **Model JSON schema** or TypeScript types for the model. This defines how a model is structured as JSON: e.g., a model object containing metadata and an array of **Sheets**, each Sheet containing a list of **Blocks** (with properties like id, type, position, parameters, etc.) and **Connections** (wires linking block outputs to inputs). It also defines how Subsystems are represented (possibly as a special block type that contains a reference to another list of blocks internally or a child sheet). Defining a clear schema (and perhaps using a validation library like Zod for it) helps maintain consistency between the front-end, simulation, and code generation logic so all interpret the model the same way.
  * **`lib/validation.ts`** – (Optional) If needed, this module could contain functions to validate a model (e.g., to ensure there are no unconnected required ports, no algebraic loops without feedback blocks, etc.). This might be used in the automation API to run model checks.

* **`/public`**: Static assets such as images or maybe example models.

  * We might include an **embedded block icon library** here. For example, icons or SVGs for each block type (Sum, Multiply, etc.) that the Block components use to visually represent themselves.
  * If we provide any documentation or offline assets (like a PDF manual, or a default example model JSON), they could reside here as well.

* **Configuration & Misc**:

  * **`next.config.js`** – Next.js configuration (if needed for custom webpack config or to set environment variables for Supabase, etc.). Usually minimal for our case.
  * **`.env.local`** – Environment variables (like Supabase URL and anon/service keys, any API secret for automation, etc.). The **automation API token** could be stored here as an environment variable used by the API route to verify incoming requests.
  * **`middleware.ts`** – (Optional) Next.js middleware to protect routes. We might use middleware to redirect unauthenticated users trying to access the `/models/...` pages back to `/login`. Alternatively, we handle this in the pages themselves by checking Supabase auth state.

This structure cleanly separates concerns: pages and API routes for routing, components for UI elements, and lib for core logic (simulation, codegen, etc.). It facilitates extensibility; for instance, adding a new block type means updating the block library (UI component + perhaps simulation and codegen handling in lib) without entangling unrelated parts.

## Database Design and Model Storage

All persistent data lives in **Supabase’s PostgreSQL** database. The key pieces of data are: **Users** and **Models**. Supabase Auth manages the Users table and authentication, so we primarily focus on the Models table. We design a `models` table roughly as:

* `id` (uuid or bigserial primary key)
* `user_id` (foreign key to auth.users – the owner of the model)
* `name` (text, model name)
* `data` (jsonb, the model JSON document)
* `updated_at` (timestamp)

The model JSON stored in the `data` column contains the full structure of the model (including all sheets, blocks, connections, and any metadata like sheet layouts or signal names). We use a JSONB column type for efficiency in storage and querying. We can query parts of the JSON if needed (e.g., maybe to find all models that use a certain block type, though not a primary requirement). Supabase’s row-level security (RLS) is configured such that each user can only select/update their own models (using `user_id = auth.uid()` in policy). This ensures privacy and data integrity.

**Application State vs. Database State:** The application maintains state both on the client and in the database. **Transient UI state** (like the current positions of blocks as the user is dragging, current simulation values, unsaved changes) lives in React state on the frontend. **Persistent state** (the saved model structure) lives in the Supabase DB as JSON. When the user is actively editing a model, changes are reflected in local state immediately for responsiveness, and the app may autosave periodically or allow the user to click "Save" to persist the JSON to Supabase. Because we avoid real-time collaboration, we don’t need constant sync; a simple debounce or save-on-demand strategy is sufficient (improving performance by reducing writes).

For simulation, the state of the simulation (values of signals at each time step, etc.) is not stored in the database – it’s either kept in memory in the browser or returned from a simulation API call. If the user stops a simulation and closes the model, they could save the final state or any logs they want by embedding them in the model JSON or by downloading a log file, but by default, simulations are ephemeral. Similarly, generated C code isn’t stored in the database; it’s produced on the fly by code generation logic when requested (keeping the DB focused on core data and not large blobs of code).

## Basics of the Simulation Model Document

A simulation **Model** is logically composed of one or more **Sheets**. Each Sheet will contain a collection of **Blocks**. We will define multiple block types from which to compose a simulation model.  Blocks have input and output **Ports**. Ports are interconnected by **Signal** wires.  As we'll see, Output Ports will have an associated data type assigned based on the nature of the block type or configuration by the user.  Signals inherit the data type of the source Output Port which they are connected to. We'll enumerate the data types supported by the application in a later section. These closly correspond to C-language data types to make for effective translation to a C-language implementation.

The simulation model is conceived with modularity and component reuse as important consideration.  Based on that idea, a model can be decomposed into **Subsystems** by the user.  As we will see, a Subsystem will have its own unique scope of blocks, names, inputs, outputs, and interconnections. In fact, the main model can be thought of as the root Subsystem to an overall model.  Subsystems may be nested inside a parent Subsystem.  There is no limit to this Subsystem nesting depth.

## Visual Modeling Canvas and Block Editor

One of the most critical parts of the app is the **visual modeling canvas** where users build diagrams. This is implemented in the frontend (React) and must be efficient and intuitive. We use a combination of HTML5 Canvas or SVG for drawing connections and perhaps a library for the diagramming foundation. For example, we could leverage an existing JS diagramming library (such as **JointJS, mxGraph, GoJS, or Draw2D**) to handle low-level drag-and-drop and rendering, but we will likely customize it heavily to enforce our specific rules (e.g., **only one wire per input port, multiple wires per output port**, and naming of signals). 

Blocks are interconnected by wires called **Signals**.  Every Signal has an an associated C-style data type.  This data type is inherited from the characteristics of the source block. Valid data types supported in the MVP will be float, double, long, bool, and one-dimensional arrays of these types. Where they appear in the user interface or internally in the model JSON document, data types specification will be text strings conforming to C-language syntax; any array dimension must be explictly specified (for example, "int", "double[3]", "bool").

Each primitive block type is defined with specific behavior:

* **Sum Block** – multiple inputs, one output (sums the inputs).
* **Multiply Block** – multiple inputs, one output (multiplies inputs).
* **Laplace Transfer Function Block** – represents a dynamic system; it has a mathematical transfer function (could be one input, one output with internal state representing the differential equation).  Internal integration of this block shold be performed by a Runge-Kutta Fourth Order Integration algorithm.
* **Signal Display Block** – an output-only block that graphically displays a signal (for simulation visualization purposes; no outputs). The Signal display block should be capable of storing a fixed number of input Signal samples from each time step of the simulation.  The number of samples should be configurable for each block. The default number of stored samples should be 1000.  Signal Display blocks are only important to the interactive simulation.  These will be ignored when generating C-code. Recorded signals will be plotted as line charts using a popular charting package such as **Recharts**.
* **Signal Logger Block** – an output-only block that logs a signal’s values during simulation (could be used to export data later; no outputs).
* **Input Port Block** – a source block representing an external input (no inputs, one output). This would be where external signals enter a subsystem or top-level model.
* **Source Block** - a source block providing either a constant or signal-generator-style signal source (no inputs, one output). Where the Source is a constant, a C-syntax constant expression sets the implied data type - examples  would include "0" - an int, 0.0f - a float, "false" - a bool, "[0.0, 0.0, 0.0]" a C-style double vector.
* **Output Port Block** – a sink block representing an external output (one input, no outputs) to mark signals that leave a subsystem or top-level model.
* **Subsystem Block** – a special block that contains a nested diagram (hierarchical composition). A Subsystem has its own internal sheet with blocks and can have defined input/output interface ports. In the parent sheet, the Subsystem block appears as a block with those ports. Subsystems can be nested to an arbitrary depth.
* **1-D Lookup Block** - a block which estimates the value of a 1-D function from an array of samples and their associated output values. The input must be a scalar int, float, or double. The output will be the same type as the input. Lookup is performed using linear interpolation. Values for inputs outside of the range of the lookup table can be either clamped to the smallest or largest lookup value or extrapolated.  Lookup is driven by similarly sized vectors: the input values (supplied in order sorted from smalled to largest value) and the corresponding output value for each. 
* **2-D Lookup Block** - this block is almost identical in function to a **1-D Lookup Block** excepts that it takes two inputs. The types of the two inputs must match and the output will be that same type. Lookup is performed using linear interpolation. Values for inputs outside of the range of the lookup table can be either clamped to the smallest or largest lookup value or extrapolated.  Lookup is driven by two vectors, an N-sized input1, an M-sized input 2, and a N by M table of corresponding output values.
* **Scale Block** - this block multiplies the input signal by a sclalar constant. It has one input port and one output port.

The **Canvas** and related components manage user interactions: Users can drag blocks from the library sidebar onto the canvas (creating a new instance of that block type in the model state), drag blocks around to reposition them, and drag from an output port to an input port to create a connection (wire). The UI provides visual feedback (highlighting compatible ports, etc.) and prevents invalid connections (for example, the app should stop the user from connecting two outputs directly or connecting an output to multiple inputs on the same port). These rules of connectivity are enforced in the Canvas component logic or the underlying diagram library, reflecting the single-source per input constraint of signal flow models.

**Scope of names** - The scope of a named signal or block name is the Subsystem in which the parent block appears. Outside this region, we cannot access the named signal or block and it is treated as undefined or undeclared.  For our purposes, the model document can be considered the root Subsystem. When a new block is instantiated, it shall be automatically assigned a unique name.  This name should follow the form <block-type-name><integer-id-number>. The expected next <integer-id-number> to be assigned should be tracked at the parent Subsystem level (e.g., at either the main model or a parent Subsystem). So, for example, the first new Sum block created in a Sunsystem would be assigned the name "Sum1", the next, "Sum2", and so on.

Under the hood, when a new connection (wire) is made, the application updates the model’s JSON structure – likely by adding an entry to a connections list that references the source block’s output and target block’s input. Conversely, deleting a wire or block updates the JSON state accordingly. Because these operations happen in the client state first, the UI is responsive; periodic saves propagate those changes to the database. The canvas likely uses a **React context or state management library** (like Zustand or Redux, if needed) to manage the current model graph in memory while editing. Given the moderate complexity, a dedicated state management solution could be beneficial to avoid prop drilling and to allow multiple components (canvas, panels) to sync up. However, we can also leverage React’s built-in context to provide the current model and a dispatcher for updates.

**Multi-Sheet Support:** The model supports multiple **Sheets** (think of these as separate canvases or pages in the same model, akin to having multiple tabs or layers in a model). The Canvas displays one Sheet at a time. This is useful for organizing large models or representing subsystems on separate pages. In the UI, this could be presented as tabbed views or a dropdown to switch sheets. Each sheet has its own canvas extent (dimensions, perhaps used to set an appropriate zoom/scale or coordinate system for the blocks on that sheet) and its own set of block instances that belong to that sheet. Connections typically exist within a sheet, except for special cases where an output port in a Subsystem might connect to an input in the parent sheet via the Subsystem block interface (we handle that via the Subsystem block definition). The data model JSON would have a structure like: `"sheets": [ { "id": 1, "name": "Main", "blocks": [...], "connections": [...] }, { "id": 2, "name": "Controller Subsystem", "blocks": [...], ... } ]`. Each sheet knows its extents (e.g., a coordinate system range for the canvas) and the layout of blocks. The **block positions** (x, y coordinates) are stored so that on loading the model, we can place each block where it was saved.

We introduce the concept of **Sheet Labels** to provide connections across sheets of a Subsystem (as with name scoping, we treat the top level model as the root Subsystem for Sheet Labeling). **Sheet Labels** referencing the same Signal name may also appean on the same sheet. Two extra Block types support the concept of **Sheet Lablels**:

* **Sheet Label Sink** - a Sheet Label Sink has one input which connects it to a source Signal. Source signal names can be specified in the UI using something combining both an input text box for freeform input combined with a dropdown showing all currently defind Signal names in the current scope (an example of such a UI control is the Material UI "Autocomplete with Free Solo" control). The block name can be assigned a name by the user and it is distinct from the Signal name. The block's asssociated Symbol inherits the type of the connected input Signal.
* **Sheet Label Source** - a Sheet Label Source block has a single output Port.  The Signal associated with the output Port can be assigned a name from a dropdown list of the names of all Sheet Label Sink blocks present in the top level model or Subsystem associated with the current Sheet being rendered on the Canvas.  The block's output Signal inherits its type from the input Signal of the associated Sheet Label Sink.

The Signal name associated with any Sheet Label block is distinct from the (unique) name assigned to the block.  This is true for both Sheet Label Sink and Sheet Label Source blocks.

Because each block (and subsystem) can have a user-defined name (especially signals going into output ports or coming from input ports), we preserve these names. Names must comply with C-style identifier naming conventions. They will be important when generating code, as they become identifier names or part of function names to make the generated code more traceable to the source model.

## Simulation Engine Design

The simulation capability allows users to run their model and see how signals change over time. Simulations will be executed on the **server** (via an API route) and return the results to the UI via APIs.

The **simulation engine** (implemented in `lib/simulationEngine.ts`) works as follows:

1. It takes a model (likely as a JavaScript object parsed from the JSON) and an optional simulation configuration (time step, total simulation time, etc. – possibly specified by the user in the UI).
2. It initializes all blocks. Some blocks have internal state or memory (e.g. a Transfer Function has internal state for its differential equation or difference equation). The engine may create a corresponding JavaScript object for each block to hold its current state and output value.
3. It then enters a loop over simulation time steps. At each step, it computes outputs of blocks that are driven by inputs. The computation order should respect data dependencies – essentially, this model forms a directed acyclic graph (DAG) if no algebraic loop, so we determine an execution order. (If there are feedback loops with delays, the engine would handle those appropriately by using previous step values for the feedback).
4. At each block, the engine computes the output based on the block type: Sum will sum its inputs, Multiply multiplies them, Transfer Function uses its internal state and formula to produce a new output (updating internal state), etc. Input Port blocks might just output a user-defined input (could be a constant or a predefined signal like a sine wave for testing), and Output Port blocks might just take a value and mark it as an output (perhaps logging it).
5. Signal Display and Logger blocks are special: they don’t affect other blocks (no output wires), but the engine knows to collect their input value each step. The Display block could directly update a UI element (like plotting on a canvas in real-time), and the Logger block stores values in an array for that run.
6. The loop continues until the simulation end time. During or after the loop, the engine can present results: e.g., plot data on a chart component, or provide a table of logged values. The user can interact with the simulation (pause, resume, step, reset) if we implement those controls. All of this simulation state (current time, current outputs, log buffers) lives in memory on the client. If a model is large or the simulation is heavy, we could move this to a Web Worker thread to avoid blocking the UI – the architecture allows swapping the engine to a worker without affecting the rest of the system.
7. Once the simulation is done, the user can see all output plots. If needed, an “Export CSV” for logged signals could be offered (which would just take the logged arrays and create a CSV file for download in the browser).

If we later needed server-side simulation (for example, to offload work or allow long-running simulations to run without keeping the browser open), the architecture can accommodate it. We would implement the `app/api/simulate` route such that it loads the model JSON from the database, runs a simulation using perhaps a Node.js library or a headless version of our simulation engine, and returns the results (likely not as detailed interactive data, but maybe summary or logs). However, for now, the client-side approach is sufficient and simpler.

## C Code Generation Service

A standout feature is generating a **PlatformIO-compatible C code library** from the model. This allows the user to deploy the logic on embedded systems (e.g., Arduino or similar microcontrollers). The code generation is initiated by the user via the UI (“Generate C Code” button), and the architecture handles this by offloading to a serverless function for processing, since file generation and packaging is better done server-side.

When the user triggers code generation for a model:

* The frontend (model editor page) calls the **Generate Code API** (e.g., `POST /api/generate-code`) either with the model’s ID or the model JSON itself. If only an ID is sent, the API route will fetch the latest model data from Supabase.
* The API route then calls the code generation module (`lib/codeGeneration.ts`). This module translates the model into C code. For each block in the model, it might map to a snippet of C:

  * It will declare a struct or variables for any block that needs state (e.g., internal states for transfer functions).
  * It will generate an **initialize function** that sets up all initial conditions (clears sums, etc.).
  * It will generate an **update step function** that, when called periodically (e.g., from a loop in an embedded program), computes all the outputs from inputs, essentially performing one simulation step. This function follows the block execution order determined by the model’s topology (similar to how the simulation engine does, but now in C).
  * Among the major elements of C-code generated for a model or Subsystem, there shall be a struct defining all inputs to the model or Subsystem, a struct defining the outputs, and a struct defining all required state variables (examples of state variables might be the staeful elements of each transfer function block).  A separate struct definition will be composed of all three of these elements.  That parent struct becomes a key element of the API to the model or Subsystem. An instance of that stuct can be craeted by a caller to create a new distinct instance of the model or Subsystem.
  * If the model has designated input/output ports (to interface with external hardware signals), those might correspond to function parameters or global variables in the generated code.
  * The code generator uses the **signal names** and block names from the model to name variables and functions in C. For example, a signal named “engine\_speed” that goes to an Output Port might result in a global variable or function output named `engine_speed`. This makes the generated code easier to integrate and understand.
* The output of the code generator is a set of C source (`.c`) and header (`.h`) files, possibly with a `platformio.ini` or library manifest if needed. For example, it would produce `src/<document-name>.c`, `src/<document-name>.h`, and any additional files for complex subsystems.
* The Next.js API route then needs to deliver these files to the user. This could be done by creating a zip archive in-memory (using a library like JSZip) and sending it as a binary response with the appropriate headers so the browser downloads it. Alternatively, the files could be uploaded to Supabase Storage or an S3 bucket and an expiring download link returned. For simplicity, generating a zip and streaming it back is straightforward.
* The user’s browser will receive the response (triggering a download of the zip file). The user can then open the zip to find a ready-to-use PlatformIO project or library containing their model’s logic in C.

The code generation service is stateless (it generates code on the fly from the model data) and does not store anything in the database. This ensures that if the model changes, the next code generation will reflect the latest model. It also keeps the database size in check (we’re not saving potentially large code text, which can be regenerated as needed).

From an extensibility perspective, the code generation is designed to be easily **extendable for new block types**: when new blocks are introduced, we update the codeGeneration module to handle their code translation. Because the model JSON includes all the needed information (block type and parameters), the code generator can use a factory or lookup pattern to handle each block type. For instance, it might have a mapping like `{ "Sum": generateSumBlockCode, "TransferFunc": generateTFBlockCode, ... }`. This modular approach allows adding new block types without rewriting the entire generator.

## Automation API and External Integrations

To support workflows like continuous integration (CI), automated model validation, or external triggers (perhaps a git hook or an IoT device requesting an update), the application provides a simple **Automation API**. This is implemented as an API route (`/api/automations/[token]` as noted in the structure) which accepts HTTP requests from authorized external sources. We deliberately separate this from the main user interface to keep the web app focused and secure.

**Security:** We generate a secret token (or use an environment-defined API key) that external systems must provide to use this API. This could be part of the URL or an HTTP header. Supabase Auth is not used here (since the caller might be a machine, not a logged-in user), so we implement a simple token check in the route handler. This avoids exposing any user-specific credentials and allows revoking/regenerating the token without affecting users.

**Functionality:** The Automation API can be designed to handle various actions:

* **Trigger Code Generation:** For example, a CI pipeline could call `POST /api/automations/[token]` with a JSON body like `{ "action": "generateCode", "modelId": "<uuid>" }`. The API route would verify the token, then fetch the model JSON from the database (using a Supabase service role key that has read access to all models, since this is a trusted environment operation) and run the code generation. It could respond with a URL to the generated code bundle or even directly attach the zip (similar to the user flow). This way, the latest code can be pulled into a firmware build process automatically.
* **Run Simulation/Tests:** Another use might be `{ "action": "simulate", "modelId": "..." }`, which triggers a server-side simulation of the model (especially if the simulation can run headless and perhaps check for certain conditions or verify outputs). The results could be returned as data (or perhaps stored to a log). This could be used for automated regression testing of models.
* **Validate Model:** `{ "action": "validateModel", "modelId": "..." }` could trigger a series of model checks (using `lib/validation.ts` if implemented) to ensure the model meets certain criteria (no missing connections, etc.), and return a pass/fail or report.

The Automation API responses are designed to be machine-readable (JSON responses with status and data), since the consumer is likely another software service. We keep these routes lightweight – they mostly orchestrate calls to the same simulation or codegen logic used by the interactive app, just without a UI. Because these run on the server, they might be allowed to take slightly longer (a CI job could wait for code generation or simulation results a few seconds), whereas the interactive UI tries to be as real-time as possible.

By having this API, we maintain a **single source of truth** for simulation and code generation logic (the functions in `lib/`), and simply expose different ways to invoke them (UI vs API). This adheres to DRY principles and ensures consistency: whether a user clicks “Simulate” in the browser or a CI calls the simulate API, the underlying computation is the same.

## State Management and Data Flow

Throughout the system, careful consideration is given to **where state lives** to maintain performance and simplicity:

* **Local UI State:** The React components hold state for instant UI feedback. For example, dragging a block around updates its position in a React state variable (or a Zustand store) immediately, so the block moves with the cursor. The wire drawing might happen in real-time as well, showing a temporary wire as the user drags from a port. This local state is authoritative during the edit session. The Canvas likely emits higher-level events (like “block moved” or “wire created”) that update the global model state in memory.
* **Global Model State in Editor:** When on the model editor page, we maintain a representation of the current model (could be the same JSON structure stored in a React state or store). All components (canvas, sidebars, panels) read and modify this state. We might use a React Context provider at the page level to supply the model and a dispatcher function to child components. For performance, consider immutable updates or state libraries that can handle large object updates efficiently. The model JSON can be large, but since it’s mostly tree-structured, focusing updates on specific parts (like a single block’s coordinates) helps.
* **Database State:** On certain triggers (on a manual save action or periodically), the in-memory model state is serialized to JSON and sent to Supabase (update the `models.data` for that model). Likewise, when opening the editor page, we load from Supabase (via server component or client fetch). We ensure the data is synced but not on every minor change (to avoid network and performance overhead).
* **Auth State:** Supabase Auth provides a session JWT which we keep on the client (Supabase JS library handles this, often storing in local storage or memory and refreshing it). We can also propagate the session to Next.js server-side (Next 13 App Router can use cookies or the auth helper library to get the user on the server). For simplicity, the app can rely on client-side checks for auth to protect most pages, but critical actions (like API routes) double-check the Supabase JWT or the automation token.
* **Simulation State:** Lives in the simulation engine context (client or server depending on mode). It’s not stored globally in React state because simulation is more of a transient process; however, some UI components (like a plot) might have internal state for the data points to display. The simulation engine could emit events or call callbacks (e.g., each time step, send new values to displays). This could be done via a simple pub-sub within the engine or by updating a React state that the Signal Display component is subscribed to. Because React re-renders could be expensive for many time steps, often simulation display is done by directly manipulating a canvas or using a chart library that imperatively updates. We might therefore have the Signal Display component just hold a reference to a chart instance and the simulation engine pushes data to it without full React state updates each step, which is a performance consideration.
* **Unsaved Changes:** To help the user, we will keep track of a “document dirty” flag – whether the model has unsaved edits. This state can be in the editor component, and if the user tries to navigate away, we can prompt them to save. It’s a minor detail but important for UX.
* **Auto Save:** every five minutes, the current state of the "dirty" model document shall be "auto-saved" to a recovery version of the document.  The recovery document should be saved to the database in the same way that the document is saved by the user - the only difference being that it is saved with a " (auto-save)" name suffix.  The auto-saved version of a document should be deleted at any point that the user explicitly saves their work, either to the current document or a new one.  The deletion should only occur after the user-initiated save successfully completes. This explicit save, would also reset the timer driving five-minute auto-save logic.

The separation of concerns in state ensures that each part of the app deals with the appropriate form of data:

1. **UI Components** – operate on in-memory state for speed.
2. **Persistent Model Storage** – only updated occasionally, which also minimizes conflict potential (since no concurrent edits).
3. **Computation (Simulation/Codegen)** – operates on a snapshot of the model state (we might pass a copy of the model JSON to the simulation engine or code generator to avoid any mutations affecting the UI state). They produce results that are either displayed or downloaded, not directly modifying the model (except maybe adding some meta info like simulation results if we choose).

## Extensibility and Performance Considerations

The architecture is designed to be **extensible**. Adding new features or blocks should require minimal changes:

* New block types would involve updating the BlockLibrarySidebar (to list it), adding a Block component or variant, and extending simulation and codegen logic to handle its behavior. Thanks to a modular design (with centralized model schema and dedicated simulation/codegen modules), this is straightforward.
* Additional features like new result visualization (say, an FFT block for signal analysis, or a custom chart) can be added as new blocks or as new panels subscribing to simulation data, without altering the core architecture.
* The use of Next.js means we can also easily add new pages, such as a **Profile page** for the user, or a **Help/Documentation** page, within the same project structure.

We also consider **performance** in the architecture:

* The visual canvas can potentially have many blocks and wires. We should use techniques like windowing or canvas layers if the number grows large. Libraries like those mentioned (JointJS, etc.) are built for many nodes and have internal optimizations. If implementing ourselves with React, we’d avoid re-rendering the whole canvas on every minor change – instead, perhaps each block is a React component that moves independently, and connections might be drawn in an SVG that updates efficiently.
* Using Next.js App Router with server components can optimize data fetching. For example, the model list page can be rendered server-side (faster initial load and SEO if needed). The model editor page could preload the model JSON on the server (so the page renders with data without an extra loading spinner). Next’s architecture allows mixing server and client components for an optimal experience.
* Supabase, being a managed Postgres, is quite scalable for our needs. By storing the heavy data (models) in JSONB, we minimize the number of tables and joins needed; a single query can retrieve the whole model. We should, however, be mindful to not fetch the model JSON more often than needed (since it could be large). This is handled by the state management as described (once loaded, keep it in memory).
* The serverless functions (API routes) should perform heavy tasks like code generation within reasonable time. If a model is extremely large, code generation could be slow, but typically it’s string processing which is fast in Node. PlatformIO code is text, so even a few thousand lines is fine to handle.
* We avoid using websockets or real-time subscriptions (since no collab or real-time multi-user updates). This simplifies the architecture and removes a class of issues around synchronization and race conditions.
* We ensure that each service is used appropriately: the database is not doing computation, the client is not doing secure data storage, etc. This clear separation means each part can be optimized or replaced if needed (for instance, if we needed to support extremely heavy simulations, we could introduce a dedicated simulation microservice or WebAssembly module without restructuring the whole app).

## Conclusion

This architecture leverages **Next.js** for a unified frontend and backend codebase, keeping the project structure organized by feature. **Supabase** provides a convenient and secure data layer with minimal overhead in developing our own backend. The design outlined above emphasizes clean separation of concerns: the *UI components* manage interactivity and visualization, the *client-side state* enables responsive editing and simulation, the *server-side API* handles heavy lifting like code export and external automation, and the *database* safely persists user models. By focusing on simplicity (a single-user editing model, on-demand persistence, no unnecessary complexity), the application remains performant and easier to maintain. The folder structure and service interactions described ensure that as the application grows (more block types, larger models, more features), the codebase remains well-organized and extensible, providing a solid foundation for a visual modeling and simulation platform.
